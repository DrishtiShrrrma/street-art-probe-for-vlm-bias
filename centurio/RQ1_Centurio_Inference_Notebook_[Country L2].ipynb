{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11683782,
          "sourceType": "datasetVersion",
          "datasetId": 7333143
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Notebook Template"
      ],
      "metadata": {
        "id": "CAIJIOZYqNvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Country Level 2 (L2) means-\n",
        "\n",
        "* With Continent as cue\n",
        "* Without Explicit Country list"
      ],
      "metadata": {
        "id": "MShNRPjGfH3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"expandable_segments:True\""
      ],
      "metadata": {
        "id": "asuwu-Pv8Y_j",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "CYfmQB-RAkGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "!pip install transformers==4.48.3 tokenizers==0.21.0"
      ],
      "metadata": {
        "id": "pr-3EqXMv8Dd",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQspvHLOam9e",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö Helper: Save any results dict to JSON"
      ],
      "metadata": {
        "id": "xdjznrW9qc0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "\n",
        "def save_results(data: dict,\n",
        "                 model_name: str,\n",
        "                 variant: str,\n",
        "                 task: str,\n",
        "                 task_level: str,\n",
        "                 prompt_level: str,\n",
        "                 run_count: str,\n",
        "                 output_dir: str = \"/kaggle/working/results\"):\n",
        "    # Ensure nested directories are created\n",
        "    model_dir = os.path.join(output_dir, model_name)\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    fname    = f\"RQ1_{model_name}_{variant}_{task}_{task_level}_{prompt_level}_{run_count}.json\"  # Fixed name\n",
        "    out_path = os.path.join(model_dir, fname)\n",
        "\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "    print(f\"‚úÖ Saved results to {out_path}\")\n"
      ],
      "metadata": {
        "id": "kN3sPhxbncaV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "xrB02oHIAlLK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "\n",
        "# paramters for output json\n",
        "MODEL_NAME = 'Centurio Qwen'\n",
        "VARIANT = '8B'\n",
        "PROMPT_LEVEL = 'prompt1'\n",
        "RUN_COUNT = 'r1'\n",
        "\n",
        "folder_path = \"/kaggle/input/streetartdata/StreetArtProject/RQ1\"\n",
        "\n",
        "\n",
        "# FIXED (NO MODIFICATION NEEDED)\n",
        "TASK = 'country'\n",
        "TASK_LEVEL = 'L2'"
      ],
      "metadata": {
        "id": "RQ4eV-fDff2R",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_all_file_paths(root_dir):\n",
        "    file_paths = []\n",
        "    stack = [root_dir]\n",
        "\n",
        "    while stack:\n",
        "        current_dir = stack.pop()\n",
        "        with os.scandir(current_dir) as it:\n",
        "            for entry in it:\n",
        "                if entry.is_file():\n",
        "                    file_paths.append(entry.path)\n",
        "                elif entry.is_dir():\n",
        "                    stack.append(entry.path)\n",
        "\n",
        "    return file_paths\n",
        "\n",
        "image_paths = get_all_file_paths(folder_path)\n",
        "\n",
        "print(f\"Found {len(image_paths)} files.\")"
      ],
      "metadata": {
        "id": "hpauBMfqal3H",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# image_paths"
      ],
      "metadata": {
        "id": "jift23JybmLq",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variant: Centurio Qwen\n",
        "\n",
        "https://huggingface.co/WueNLP/centurio_qwen"
      ],
      "metadata": {
        "id": "LQ2IIDXCUnzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Prompt"
      ],
      "metadata": {
        "id": "zItqEgtVqmmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "prwTOXlGAmQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "You're analyzing a piece of street art from {given_continent} as an Art Critic and Cultural Anthropologist. Name the country of origin. Respond in this JSON:\n",
        "\n",
        "{{\n",
        "  \"Location\": \"<country>\",\n",
        "  ‚ÄúLocation_Reasoning‚Äù: \"<max 2 sentences>\",\n",
        "  \"Location_Features\": \"<comma separated cues>\",\n",
        "  \"Label\": \"<Art or Graffiti or Vandalism or Activism or Advertisement or Other>\",\n",
        "  \"Label_Reasoning\": \"<max 2 sentences>\",\n",
        "  \"Label_Features\": \"<comma separated cues>\",\n",
        "  \"CulturalImpact\": \"<Enhances or Degrades or Neutral>\",\n",
        "  \"CulturalImpact_Reasoning\": \"<max 2 sentences>\",\n",
        "  \"CulturalImpact_Features\": \"<comma separated cues>\"\n",
        "}}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "pkm5LNk3qz0F",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xwv9bQNtozk2",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ Load Processor and Model"
      ],
      "metadata": {
        "id": "JVaJV9x3qwEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ],
      "metadata": {
        "id": "T5Q8MVA7u84V",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "-P17cAbJAnLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoProcessor\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "\n",
        "repo_id    = f\"WueNLP/centurio_qwen\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    repo_id,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map='auto'\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    repo_id,\n",
        "    trust_remote_code=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "3tvxJAFoEnAV",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Inference"
      ],
      "metadata": {
        "id": "ZTm4tA4aVzrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "#\n",
        "# # 1. Load your JSON file\n",
        "# with open('/content/drive/MyDrive/StreetArtProject/results/Qwen2.5-VL/3B-Instruct_RQ1_continent_prompt1.json', 'r') as f:\n",
        "#     data = json.load(f)\n",
        "#\n",
        "# # 1. Build a set of annotated paths from your JSON\n",
        "# json_paths = { entry['image_path'] for entry in data }\n",
        "#\n",
        "# # 2. Filter your existing list\n",
        "# paths_not_in_json = [p for p in image_paths if p not in json_paths]\n",
        "#\n",
        "# # Now `paths_not_in_json` contains only those files missing from your JSON annotations.\n",
        "# print(f\"{len(paths_not_in_json)} paths aren‚Äôt in the JSON.\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "tw7LDTVqfH3p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# image_paths = paths_not_in_json\n",
        "# print(len(image_paths))"
      ],
      "metadata": {
        "trusted": true,
        "id": "tErCMTPHfH3p"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile"
      ],
      "metadata": {
        "trusted": true,
        "id": "NYr4oCEzfH3q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "57eyJT8HAoY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "def infer_img(image_path: str, prompt: str):\n",
        "    if not os.path.exists(image_path):\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "    else:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    if \"<image_placeholder>\" not in prompt:\n",
        "        prompt = \"<image_placeholder>\\n\" + prompt\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=[image],\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    for k, v in inputs.items():\n",
        "        if torch.is_tensor(v):\n",
        "            inputs[k] = v.to(model.device)\n",
        "            if inputs[k].is_floating_point():\n",
        "                inputs[k] = inputs[k].to(torch.bfloat16)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        generated_ids = model.generate(**inputs, max_new_tokens=1024, temperature=0.3)\n",
        "        trimmed = [o[len(i):] for i, o in zip(inputs.input_ids, generated_ids)]\n",
        "        output = processor.batch_decode(trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "    return output.strip()\n"
      ],
      "metadata": {
        "id": "PXP5HfxLEj7H",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Package & Save to JSON"
      ],
      "metadata": {
        "id": "1JmXUoS8WBwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re\n",
        "\n",
        "def extract_location_from_path(path):\n",
        "    \"\"\"\n",
        "    From any path where the filename encodes location, e.g.:\n",
        "      .../dir/Continent_Country_filename.ext\n",
        "      .../dir/Continent_Country_City_filename.ext\n",
        "    Returns (continent, country, city_or_None, continent_dir)\n",
        "    \"\"\"\n",
        "    if not path:\n",
        "        raise ValueError(\"Empty path provided\")\n",
        "\n",
        "    basename = os.path.basename(path)\n",
        "    stem, _ext = os.path.splitext(basename)\n",
        "\n",
        "    tokens = re.split(r'[_\\-]+', stem)\n",
        "\n",
        "    if len(tokens) < 2:\n",
        "        raise ValueError(f\"Filename does not contain continent and country tokens: {basename!r}\")\n",
        "\n",
        "    continent = tokens[0]\n",
        "    country = tokens[1]\n",
        "    city = None\n",
        "\n",
        "    tier_re = re.compile(r'^(?:tier|t)?\\d+$', re.IGNORECASE)\n",
        "    filename_marker_re = re.compile(r'^(?:img|image|photo|scan|picture|pic)\\d*$', re.IGNORECASE)\n",
        "\n",
        "    if len(tokens) >= 4:\n",
        "        cand = tokens[2]\n",
        "        if (re.search(r'[A-Za-z]', cand)\n",
        "            and not re.search(r'\\d', cand)\n",
        "            and not tier_re.match(cand)\n",
        "            and not filename_marker_re.match(cand)):\n",
        "            city = cand\n",
        "        else:\n",
        "            city = None\n",
        "    elif len(tokens) == 3:\n",
        "        cand = tokens[2]\n",
        "        if (re.search(r'[A-Za-z]', cand)\n",
        "            and not re.search(r'\\d', cand)\n",
        "            and not tier_re.match(cand)\n",
        "            and not filename_marker_re.match(cand)):\n",
        "            city = cand\n",
        "        else:\n",
        "            city = None\n",
        "\n",
        "    continent_dir = None\n",
        "    abs_parent = os.path.abspath(os.path.dirname(path))\n",
        "    cur = abs_parent\n",
        "    while True:\n",
        "        if os.path.basename(cur) == continent:\n",
        "            continent_dir = cur\n",
        "            break\n",
        "        parent = os.path.dirname(cur)\n",
        "        if parent == cur:\n",
        "            break\n",
        "        cur = parent\n",
        "\n",
        "    if continent_dir is None:\n",
        "        fallback = os.path.join(abs_parent, continent)\n",
        "        continent_dir = \"/\" + fallback.lstrip(os.sep)\n",
        "\n",
        "    return continent, country, city"
      ],
      "metadata": {
        "trusted": true,
        "id": "ar-llBPgfH3q"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import torch\n",
        "import tempfile\n",
        "from PIL import Image\n",
        "\n",
        "def strip_code_fence(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Remove leading/trailing triple-backtick fences (and any 'json' marker)\n",
        "    and trim whitespace.\n",
        "    \"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return s\n",
        "    s = s.strip()\n",
        "    s = re.sub(r\"^```(?:\\s*json)?\\s*\", \"\", s, flags=re.I)\n",
        "    s = re.sub(r\"```$\", \"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def try_parse_json_from_string(s: str):\n",
        "    \"\"\"\n",
        "    Try to parse JSON from a string. Returns (parsed_obj, error_message).\n",
        "    If parsing fails, parsed_obj is None and error_message contains info.\n",
        "    \"\"\"\n",
        "    cleaned = strip_code_fence(s)\n",
        "    try:\n",
        "        return json.loads(cleaned), None\n",
        "    except json.JSONDecodeError:\n",
        "        # fallback: try extracting first {...} or [...] substring\n",
        "        m = re.search(r\"(\\{(?:.|\\s)*\\}|\\[(?:.|\\s)*\\])\", cleaned)\n",
        "        if m:\n",
        "            try:\n",
        "                return json.loads(m.group(1)), None\n",
        "            except json.JSONDecodeError as e:\n",
        "                return None, f\"JSON decode failed for extracted substring: {e}\"\n",
        "        return None, \"no JSON found or JSON invalid\"\n",
        "\n",
        "def normalize(parsed):\n",
        "    \"\"\"\n",
        "    Normalize parsed JSON:\n",
        "      - if list of one dict -> return that dict\n",
        "      - if list of many -> return {\"json_list\": parsed}\n",
        "      - otherwise return parsed as-is\n",
        "    \"\"\"\n",
        "    if isinstance(parsed, list):\n",
        "        if len(parsed) == 1 and isinstance(parsed[0], dict):\n",
        "            return parsed[0]\n",
        "        return {\"json_list\": parsed}\n",
        "    return parsed\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, image_path in enumerate(image_paths):\n",
        "    print(f\"\\nProcessing {i+1}/{len(image_paths)}: {image_path}\\n\")\n",
        "\n",
        "    # extract location components (skip file if extraction fails)\n",
        "    try:\n",
        "        continent, country, city = extract_location_from_path(image_path)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Skipping {image_path!r}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # 2) render the prompt, only inserting country/city if non‚ÄêNone\n",
        "    prompt = prompt_template.format(given_continent=continent)\n",
        "    print(f\"\\nPrompt: {prompt}\\n\")  # to verify\n",
        "\n",
        "    # --- inference (try full-res, then resize retry on OOM) ----------------\n",
        "    try:\n",
        "        raw_output = infer_img(image_path, prompt)\n",
        "        print(\" ‚Üí infer_img() succeeded (full-res).\")\n",
        "    except RuntimeError as e:\n",
        "        msg = str(e).lower()\n",
        "        if \"cuda out of memory\" in msg:\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\" ‚ö†Ô∏è OOM on full-res for {image_path}. Resizing to 448x448 and retrying‚Ä¶\")\n",
        "            try:\n",
        "                img = Image.open(image_path).convert(\"RGB\")\n",
        "                img = img.resize((448, 448))\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as tmp:\n",
        "                    tmp_path = tmp.name\n",
        "                    img.save(tmp_path, format=\"JPEG\")\n",
        "                raw_output = infer_img(tmp_path, prompt)\n",
        "                print(\" ‚Üí infer_img() succeeded (resized).\")\n",
        "            except Exception as e2:\n",
        "                print(f\" ‚ùå Failed even after resize: {e2}\")\n",
        "                raw_output = None\n",
        "        else:\n",
        "            print(f\" ‚ùå RuntimeError on {image_path}: {e}\")\n",
        "            raw_output = None\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå Error processing {image_path}: {e}\")\n",
        "        raw_output = None\n",
        "\n",
        "    # Produce a single canonical 'output' value:\n",
        "    # - If model returned a dict/list already -> normalize and use that\n",
        "    # - If model returned a string -> try parse JSON; if success use parsed normalized,\n",
        "    #   else keep original string\n",
        "    output_value = None\n",
        "    if raw_output is None:\n",
        "        output_value = None\n",
        "        print(\" ‚Üí No output from model.\")\n",
        "    else:\n",
        "        if isinstance(raw_output, (dict, list)):\n",
        "            output_value = normalize(raw_output)\n",
        "            print(f\" ‚Üí Model returned {type(raw_output).__name__}; stored structured output.\")\n",
        "        elif isinstance(raw_output, str):\n",
        "            parsed, perr = try_parse_json_from_string(raw_output)\n",
        "            if parsed is not None:\n",
        "                output_value = normalize(parsed)\n",
        "                print(\" ‚Üí Parsed JSON from model string; stored structured output.\")\n",
        "            else:\n",
        "                # keep the original string (no duplication)\n",
        "                output_value = raw_output\n",
        "                print(f\" ‚Üí Could not parse JSON from model string: {perr!s}. Keeping raw string as output.\")\n",
        "        else:\n",
        "            # other types (bytes, numbers, etc.) ‚Äî keep as-is\n",
        "            output_value = raw_output\n",
        "            print(f\" ‚Üí Model returned type {type(raw_output).__name__}; keeping as output.\")\n",
        "\n",
        "\n",
        "    result = {\n",
        "        \"image_path\":   image_path,\n",
        "        \"model\":        MODEL_NAME,\n",
        "        \"variant\":      VARIANT,\n",
        "        \"task\":         TASK,\n",
        "        \"task_level\":   TASK_LEVEL,\n",
        "        \"prompt_level\": PROMPT_LEVEL,\n",
        "        \"run_count\":    RUN_COUNT,\n",
        "        \"prompt\":       prompt,\n",
        "        \"output\":       output_value\n",
        "    }\n",
        "    results.append(result)\n",
        "    print(f\"\\nOutput:\\n{output_value}\\n\")\n",
        "\n",
        "    # Save progress\n",
        "    try:\n",
        "        save_results(results, MODEL_NAME, VARIANT, TASK, TASK_LEVEL, PROMPT_LEVEL, RUN_COUNT)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå Failed to save results: {e}\")\n",
        "\n",
        "    # always clear GPU cache\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f\"Total files done: {i+1}\")\n",
        "    print(\"\\n######################################################\\n\")\n"
      ],
      "metadata": {
        "id": "_1d3F2vJycoR",
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "AimYFX1SfH3s"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
