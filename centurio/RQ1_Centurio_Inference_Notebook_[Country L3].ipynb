{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 11683782,
          "sourceType": "datasetVersion",
          "datasetId": 7333143
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Notebook Template"
      ],
      "metadata": {
        "id": "CAIJIOZYqNvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Country Level 3 (L3) means-\n",
        "\n",
        "* With Continent as cue\n",
        "* With Explicit Country list"
      ],
      "metadata": {
        "id": "FI7w45YnbC3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"]=\"expandable_segments:True\""
      ],
      "metadata": {
        "id": "asuwu-Pv8Y_j",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:47:09.782288Z",
          "iopub.execute_input": "2025-10-06T09:47:09.782542Z",
          "iopub.status.idle": "2025-10-06T09:47:09.792500Z",
          "shell.execute_reply.started": "2025-10-06T09:47:09.782518Z",
          "shell.execute_reply": "2025-10-06T09:47:09.791703Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "u0joxjB6AULA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "!pip install transformers==4.48.3 tokenizers==0.21.0"
      ],
      "metadata": {
        "id": "pr-3EqXMv8Dd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:47:09.793758Z",
          "iopub.execute_input": "2025-10-06T09:47:09.794002Z",
          "iopub.status.idle": "2025-10-06T09:49:15.898259Z",
          "shell.execute_reply.started": "2025-10-06T09:47:09.793980Z",
          "shell.execute_reply": "2025-10-06T09:49:15.897314Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DQspvHLOam9e",
        "trusted": true,
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö Helper: Save any results dict to JSON"
      ],
      "metadata": {
        "id": "xdjznrW9qc0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "\n",
        "def save_results(data: dict,\n",
        "                 model_name: str,\n",
        "                 variant: str,\n",
        "                 task: str,\n",
        "                 task_level: str,\n",
        "                 prompt_level: str,\n",
        "                 run_count: str,\n",
        "                 output_dir: str = \"/kaggle/working/results\"):\n",
        "    # Ensure nested directories are created\n",
        "    model_dir = os.path.join(output_dir, model_name)\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    fname    = f\"RQ1_{model_name}_{variant}_{task}_{task_level}_{prompt_level}_{run_count}.json\"  # Fixed name\n",
        "    out_path = os.path.join(model_dir, fname)\n",
        "\n",
        "    with open(out_path, \"w\") as f:\n",
        "        json.dump(data, f, indent=4)\n",
        "    print(f\"‚úÖ Saved results to {out_path}\")\n"
      ],
      "metadata": {
        "id": "kN3sPhxbncaV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:49:15.899482Z",
          "iopub.execute_input": "2025-10-06T09:49:15.899750Z",
          "iopub.status.idle": "2025-10-06T09:49:15.905557Z",
          "shell.execute_reply.started": "2025-10-06T09:49:15.899727Z",
          "shell.execute_reply": "2025-10-06T09:49:15.904790Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "pAcIsMuWAYUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "\n",
        "# paramters for output json\n",
        "MODEL_NAME = 'Centurio Qwen'\n",
        "VARIANT = '8B'\n",
        "PROMPT_LEVEL = 'prompt1'\n",
        "RUN_COUNT = 'r1'\n",
        "\n",
        "folder_path = \"/kaggle/input/streetartdata/StreetArtProject/RQ1\"\n",
        "\n",
        "\n",
        "# FIXED (NO MODIFICATION NEEDED)\n",
        "TASK = 'country'\n",
        "TASK_LEVEL = 'L3'"
      ],
      "metadata": {
        "id": "RQ4eV-fDff2R",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:49:15.906906Z",
          "iopub.execute_input": "2025-10-06T09:49:15.907144Z",
          "iopub.status.idle": "2025-10-06T09:49:15.917008Z",
          "shell.execute_reply.started": "2025-10-06T09:49:15.907128Z",
          "shell.execute_reply": "2025-10-06T09:49:15.916432Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_all_file_paths(root_dir):\n",
        "    file_paths = []\n",
        "    stack = [root_dir]\n",
        "\n",
        "    while stack:\n",
        "        current_dir = stack.pop()\n",
        "        with os.scandir(current_dir) as it:\n",
        "            for entry in it:\n",
        "                if entry.is_file():\n",
        "                    file_paths.append(entry.path)\n",
        "                elif entry.is_dir():\n",
        "                    stack.append(entry.path)\n",
        "\n",
        "    return file_paths\n",
        "\n",
        "image_paths = get_all_file_paths(folder_path)\n",
        "\n",
        "print(f\"Found {len(image_paths)} files.\")"
      ],
      "metadata": {
        "id": "hpauBMfqal3H",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:49:15.917595Z",
          "iopub.execute_input": "2025-10-06T09:49:15.917793Z",
          "iopub.status.idle": "2025-10-06T09:49:16.070882Z",
          "shell.execute_reply.started": "2025-10-06T09:49:15.917773Z",
          "shell.execute_reply": "2025-10-06T09:49:16.070380Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# image_paths"
      ],
      "metadata": {
        "id": "jift23JybmLq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:49:16.071511Z",
          "iopub.execute_input": "2025-10-06T09:49:16.071735Z",
          "iopub.status.idle": "2025-10-06T09:49:16.075080Z",
          "shell.execute_reply.started": "2025-10-06T09:49:16.071715Z",
          "shell.execute_reply": "2025-10-06T09:49:16.074380Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Variant: Centurio Qwen\n",
        "\n",
        "https://huggingface.co/WueNLP/centurio_qwen"
      ],
      "metadata": {
        "id": "LQ2IIDXCUnzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Prompt"
      ],
      "metadata": {
        "id": "zItqEgtVqmmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "SVsrov5eAZva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "This art is from continent **{given_continent}**. Which country is it most likely from? *(Only choose one from [{country_list}])*\n",
        "\n",
        "Classify it with one word: art, vandalism, protest, decoration, advertisement, or other.\n",
        "\n",
        "Finally, If this particular mural were banned, would it improve or harm urban life in *this location*, would urban life improve or harm? Briefly justify.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "B40bKt7o2xfi",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:49:16.075777Z",
          "iopub.execute_input": "2025-10-06T09:49:16.076284Z",
          "iopub.status.idle": "2025-10-06T09:49:16.085681Z",
          "shell.execute_reply.started": "2025-10-06T09:49:16.076259Z",
          "shell.execute_reply": "2025-10-06T09:49:16.085168Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "xsIvgWakbC3L"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ Load Processor and Model"
      ],
      "metadata": {
        "id": "JVaJV9x3qwEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from huggingface_hub import notebook_login\n",
        "# notebook_login()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:49:16.086412Z",
          "iopub.execute_input": "2025-10-06T09:49:16.086615Z",
          "iopub.status.idle": "2025-10-06T09:49:16.097550Z",
          "shell.execute_reply.started": "2025-10-06T09:49:16.086592Z",
          "shell.execute_reply": "2025-10-06T09:49:16.096969Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "7cneyVXcbC3L"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "brOecZXQAfke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoProcessor\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "import os\n",
        "\n",
        "repo_id    = f\"WueNLP/centurio_qwen\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    repo_id,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map='auto'\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(\n",
        "    repo_id,\n",
        "    trust_remote_code=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "3tvxJAFoEnAV",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:49:16.099509Z",
          "iopub.execute_input": "2025-10-06T09:49:16.100054Z",
          "iopub.status.idle": "2025-10-06T09:52:07.251956Z",
          "shell.execute_reply.started": "2025-10-06T09:49:16.100009Z",
          "shell.execute_reply": "2025-10-06T09:52:07.251406Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Inference"
      ],
      "metadata": {
        "id": "ZTm4tA4aVzrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "#\n",
        "# # 1. Load your JSON file\n",
        "# with open('/content/drive/MyDrive/StreetArtProject/results/Qwen2.5-VL/3B-Instruct_RQ1_continent_prompt1.json', 'r') as f:\n",
        "#     data = json.load(f)\n",
        "#\n",
        "# # 1. Build a set of annotated paths from your JSON\n",
        "# json_paths = { entry['image_path'] for entry in data }\n",
        "#\n",
        "# # 2. Filter your existing list\n",
        "# paths_not_in_json = [p for p in image_paths if p not in json_paths]\n",
        "#\n",
        "# # Now `paths_not_in_json` contains only those files missing from your JSON annotations.\n",
        "# print(f\"{len(paths_not_in_json)} paths aren‚Äôt in the JSON.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:52:07.252797Z",
          "iopub.execute_input": "2025-10-06T09:52:07.253231Z",
          "iopub.status.idle": "2025-10-06T09:52:07.256818Z",
          "shell.execute_reply.started": "2025-10-06T09:52:07.253203Z",
          "shell.execute_reply": "2025-10-06T09:52:07.256167Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "qcuCb003bC3M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# image_paths = paths_not_in_json\n",
        "# print(len(image_paths))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:52:07.257645Z",
          "iopub.execute_input": "2025-10-06T09:52:07.257897Z",
          "iopub.status.idle": "2025-10-06T09:52:07.269214Z",
          "shell.execute_reply.started": "2025-10-06T09:52:07.257876Z",
          "shell.execute_reply": "2025-10-06T09:52:07.268691Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "TUkwSWABbC3M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:52:07.269875Z",
          "iopub.execute_input": "2025-10-06T09:52:07.270108Z",
          "iopub.status.idle": "2025-10-06T09:52:07.280278Z",
          "shell.execute_reply.started": "2025-10-06T09:52:07.270083Z",
          "shell.execute_reply": "2025-10-06T09:52:07.279644Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "ydgITTVCbC3M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "üî® TO BE MODIFIED üî®"
      ],
      "metadata": {
        "id": "mz8Nuj3rAbPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE MODIFIED\n",
        "\n",
        "def infer_img(image_path: str, prompt: str):\n",
        "    if not os.path.exists(image_path):\n",
        "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
        "    else:\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "    if \"<image_placeholder>\" not in prompt:\n",
        "        prompt = \"<image_placeholder>\\n\" + prompt\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=[image],\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    for k, v in inputs.items():\n",
        "        if torch.is_tensor(v):\n",
        "            inputs[k] = v.to(model.device)\n",
        "            if inputs[k].is_floating_point():\n",
        "                inputs[k] = inputs[k].to(torch.bfloat16)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        generated_ids = model.generate(**inputs, max_new_tokens=1024, temperature=0.3)\n",
        "        trimmed = [o[len(i):] for i, o in zip(inputs.input_ids, generated_ids)]\n",
        "        output = processor.batch_decode(trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "    return output.strip()\n"
      ],
      "metadata": {
        "id": "PXP5HfxLEj7H",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:52:07.281177Z",
          "iopub.execute_input": "2025-10-06T09:52:07.281389Z",
          "iopub.status.idle": "2025-10-06T09:52:07.293162Z",
          "shell.execute_reply.started": "2025-10-06T09:52:07.281375Z",
          "shell.execute_reply": "2025-10-06T09:52:07.292457Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Package & Save to JSON"
      ],
      "metadata": {
        "id": "1JmXUoS8WBwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re\n",
        "from copy import deepcopy\n",
        "\n",
        "def extract_location_from_path(path):\n",
        "    \"\"\"\n",
        "    From any path where the filename encodes location, e.g.:\n",
        "      .../dir/Continent_Country_filename.ext\n",
        "      .../dir/Continent_Country_City_filename.ext\n",
        "    Returns (continent, country, city_or_None, continent_dir)\n",
        "    \"\"\"\n",
        "    if not path:\n",
        "        raise ValueError(\"Empty path provided\")\n",
        "\n",
        "    basename = os.path.basename(path)\n",
        "    stem, _ext = os.path.splitext(basename)\n",
        "\n",
        "    tokens = re.split(r'[_\\-]+', stem)\n",
        "\n",
        "    if len(tokens) < 2:\n",
        "        raise ValueError(f\"Filename does not contain continent and country tokens: {basename!r}\")\n",
        "\n",
        "    continent = tokens[0]\n",
        "    country = tokens[1]\n",
        "    city = None\n",
        "\n",
        "    tier_re = re.compile(r'^(?:tier|t)?\\d+$', re.IGNORECASE)\n",
        "    filename_marker_re = re.compile(r'^(?:img|image|photo|scan|picture|pic)\\d*$', re.IGNORECASE)\n",
        "\n",
        "    if len(tokens) >= 4:\n",
        "        cand = tokens[2]\n",
        "        if (re.search(r'[A-Za-z]', cand)\n",
        "            and not re.search(r'\\d', cand)\n",
        "            and not tier_re.match(cand)\n",
        "            and not filename_marker_re.match(cand)):\n",
        "            city = cand\n",
        "        else:\n",
        "            city = None\n",
        "    elif len(tokens) == 3:\n",
        "        cand = tokens[2]\n",
        "        if (re.search(r'[A-Za-z]', cand)\n",
        "            and not re.search(r'\\d', cand)\n",
        "            and not tier_re.match(cand)\n",
        "            and not filename_marker_re.match(cand)):\n",
        "            city = cand\n",
        "        else:\n",
        "            city = None\n",
        "\n",
        "    continent_dir = None\n",
        "    abs_parent = os.path.abspath(os.path.dirname(path))\n",
        "    cur = abs_parent\n",
        "    while True:\n",
        "        if os.path.basename(cur) == continent:\n",
        "            continent_dir = cur\n",
        "            break\n",
        "        parent = os.path.dirname(cur)\n",
        "        if parent == cur:\n",
        "            break\n",
        "        cur = parent\n",
        "\n",
        "    if continent_dir is None:\n",
        "        fallback = os.path.join(abs_parent, continent)\n",
        "        continent_dir = \"/\" + fallback.lstrip(os.sep)\n",
        "\n",
        "    return continent, country, city, continent_dir\n",
        "\n",
        "\n",
        "\n",
        "# --- Data: 9 countries per continent (TOP(3), MIDDLE(3), LAST(3)) ---\n",
        "CONTINENT_COUNTRIES = {\n",
        "    \"Africa\": [\n",
        "        \"Nigeria\", \"South Africa\", \"Egypt\",    # TOP (3)\n",
        "        \"Seychelles\", \"Comoros\", \"Cape Verde\", # MIDDLE (3)\n",
        "        \"Mozambique\", \"Rwanda\", \"Botswana\"     # LAST (3)\n",
        "    ],\n",
        "    \"Asia\": [\n",
        "        \"China\", \"India\", \"Indonesia\",\n",
        "        \"United Arab Emirates\", \"Singapore\", \"Israel\",\n",
        "        \"Timor-Leste\", \"Maldives\", \"Brunei\"\n",
        "    ],\n",
        "    \"Europe\": [\n",
        "        \"Russia\", \"Germany\", \"United Kingdom\",\n",
        "        \"Denmark\", \"Lithuania\", \"Slovakia\",\n",
        "        \"Monaco\", \"Gibraltar\", \"San Marino\"\n",
        "    ],\n",
        "    \"North America\": [\n",
        "        \"United States\", \"Mexico\", \"Canada\",\n",
        "        \"Saint Lucia\", \"Guyana\", \"Bahamas\",\n",
        "        \"British Virgin Islands\", \"Anguilla\", \"Montserrat\"\n",
        "    ],\n",
        "    \"South America\": [\n",
        "        \"Brazil\", \"Argentina\", \"Colombia\",\n",
        "        \"Venezuela\", \"Chile\", \"Ecuador\",\n",
        "        \"Paraguay\", \"Uruguay\", \"Falkland Islands\"\n",
        "    ],\n",
        "}\n",
        "\n",
        "# --- Normalization helpers ---\n",
        "def _norm(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Minimal normalizer used for matching:\n",
        "      - lowercases and removes non-alphanumeric characters.\n",
        "    Use this to compare filename tokens to canonical country names.\n",
        "    \"\"\"\n",
        "    return re.sub(r'[^a-z0-9]', '', (s or '').lower())\n",
        "\n",
        "def get_countries(continent: str, image_path: str = None):\n",
        "    \"\"\"\n",
        "    Return the continent's country list (copy) and optionally apply filename-based replacement.\n",
        "\n",
        "    Behavior:\n",
        "      - continent: case-insensitive continent name (e.g. \"Africa\").\n",
        "      - image_path: optional filename like \"Continent_Country_..._[TOP|MIDDLE|LAST].ext\".\n",
        "        * The country token is taken from the SECOND underscore-separated token (parts[1]).\n",
        "        * If that country is NOT already in the continent list, the function replaces the\n",
        "          country at the group index with the parsed country:\n",
        "            TOP    -> index 2\n",
        "            MIDDLE -> index 5\n",
        "            LAST   -> index 8\n",
        "          (If tag is missing the function uses index 5 by current logic.)\n",
        "    Returns:\n",
        "      (countries_list_copy, info_dict)\n",
        "        - countries_list_copy: a shallow copy of the continent list with any replacement applied.\n",
        "        - info_dict: { used_continent, filename_country, tag, matched, added, removed, index }\n",
        "    Raises:\n",
        "      ValueError: if the provided continent is not recognized.\n",
        "    \"\"\"\n",
        "    # find canonical continent key\n",
        "    cont_key = None\n",
        "    for k in CONTINENT_COUNTRIES:\n",
        "        if _norm(k) == _norm(continent):\n",
        "            cont_key = k\n",
        "            break\n",
        "    if not cont_key:\n",
        "        raise ValueError(f\"Unknown continent: {continent!r}\")\n",
        "\n",
        "    arr = deepcopy(CONTINENT_COUNTRIES[cont_key])\n",
        "    info = {\"used_continent\": cont_key, \"filename_country\": None, \"tag\": None,\n",
        "            \"matched\": None, \"added\": None, \"removed\": None, \"index\": None}\n",
        "\n",
        "    if not image_path:\n",
        "        return arr, info\n",
        "\n",
        "    base = os.path.basename(image_path)\n",
        "    name, _ = os.path.splitext(base)\n",
        "    parts = name.split('_')\n",
        "    if len(parts) < 2:\n",
        "        return arr, info  # can't parse a country token\n",
        "\n",
        "    # country is the second token (parts[1]) per user's filename format\n",
        "    country_token = parts[1]\n",
        "    # detect tag if last token is TOP/MIDDLE/LAST\n",
        "    tag = parts[-1].upper() if parts[-1].upper() in (\"TOP\", \"MIDDLE\", \"LAST\") else None\n",
        "\n",
        "    # build display country from single token: replace dashes with space and title-case\n",
        "    display_country = country_token.replace('-', ' ').title()\n",
        "    info[\"filename_country\"] = display_country\n",
        "    info[\"tag\"] = tag\n",
        "\n",
        "    # check if already present (using normalization)\n",
        "    for c in arr:\n",
        "        if _norm(c) == _norm(display_country):\n",
        "            info[\"matched\"] = c\n",
        "            return arr, info  # already exists ‚Äî no change\n",
        "\n",
        "    # Not present: replace at group index\n",
        "    tag_to_idx = {\"TOP\": 2, \"MIDDLE\": 5, \"LAST\": 8}\n",
        "    remove_idx = tag_to_idx.get(tag, 5)\n",
        "    remove_idx = max(0, min(remove_idx, len(arr) - 1))\n",
        "\n",
        "    removed = arr.pop(remove_idx)\n",
        "    arr.insert(remove_idx, display_country)\n",
        "\n",
        "    info[\"added\"] = display_country\n",
        "    info[\"removed\"] = removed\n",
        "    info[\"index\"] = remove_idx\n",
        "    return arr, info\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:52:07.293902Z",
          "iopub.execute_input": "2025-10-06T09:52:07.294152Z",
          "iopub.status.idle": "2025-10-06T09:52:07.311558Z",
          "shell.execute_reply.started": "2025-10-06T09:52:07.294133Z",
          "shell.execute_reply": "2025-10-06T09:52:07.310985Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "UyLpgSInbC3M"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import os\n",
        "import torch\n",
        "\n",
        "def strip_code_fence(s: str) -> str:\n",
        "    \"\"\"\n",
        "    Remove leading/trailing triple-backtick fences (and any 'json' marker)\n",
        "    and trim whitespace.\n",
        "    \"\"\"\n",
        "    if not isinstance(s, str):\n",
        "        return s\n",
        "    s = s.strip()\n",
        "    s = re.sub(r\"^```(?:\\s*json)?\\s*\", \"\", s, flags=re.I)\n",
        "    s = re.sub(r\"```$\", \"\", s)\n",
        "    return s.strip()\n",
        "\n",
        "def try_parse_json_from_string(s: str):\n",
        "    \"\"\"\n",
        "    Try to parse JSON from a string. Returns (parsed_obj, error_message).\n",
        "    If parsing fails, parsed_obj is None and error_message contains info.\n",
        "    \"\"\"\n",
        "    cleaned = strip_code_fence(s)\n",
        "    try:\n",
        "        return json.loads(cleaned), None\n",
        "    except json.JSONDecodeError:\n",
        "        # fallback: try extracting first {...} or [...] substring\n",
        "        m = re.search(r\"(\\{(?:.|\\s)*\\}|\\[(?:.|\\s)*\\])\", cleaned)\n",
        "        if m:\n",
        "            try:\n",
        "                return json.loads(m.group(1)), None\n",
        "            except json.JSONDecodeError as e:\n",
        "                return None, f\"JSON decode failed for extracted substring: {e}\"\n",
        "        return None, \"no JSON found or JSON invalid\"\n",
        "\n",
        "def normalize(parsed):\n",
        "    \"\"\"\n",
        "    Normalize parsed JSON:\n",
        "      - if list of one dict -> return that dict\n",
        "      - if list of many -> return {\"json_list\": parsed}\n",
        "      - otherwise return parsed as-is\n",
        "    \"\"\"\n",
        "    if isinstance(parsed, list):\n",
        "        if len(parsed) == 1 and isinstance(parsed[0], dict):\n",
        "            return parsed[0]\n",
        "        return {\"json_list\": parsed}\n",
        "    return parsed\n",
        "\n",
        "results = []\n",
        "\n",
        "for i, image_path in enumerate(image_paths):\n",
        "    print(f\"\\nProcessing {i+1}/{len(image_paths)}: {image_path}\\n\")\n",
        "\n",
        "    # extract location components (skip file if extraction fails)\n",
        "    try:\n",
        "        continent, country, city, continent_dir = extract_location_from_path(image_path)\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ö†Ô∏è Skipping {image_path!r}: {e}\")\n",
        "        continue\n",
        "\n",
        "    # list countries from the continent\n",
        "    try:\n",
        "        countries, info = get_countries(continent, image_path)\n",
        "        country_list = \", \".join(countries)\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ö†Ô∏è Could not list countries in {continent_dir!r}: {e}\")\n",
        "        country_list = \"\"\n",
        "\n",
        "    # render the prompt, only inserting country_list if non-empty\n",
        "    prompt = prompt_template.format(\n",
        "        given_continent=continent,\n",
        "        country_list=country_list\n",
        "    )\n",
        "    print(f\" Prompt: {prompt}\\n\")\n",
        "\n",
        "    # --- inference (try full-res, then resize retry on OOM) ----------------\n",
        "    try:\n",
        "        raw_output = infer_img(image_path, prompt)\n",
        "        print(\" ‚Üí infer_img() succeeded (full-res).\")\n",
        "    except RuntimeError as e:\n",
        "        msg = str(e).lower()\n",
        "        if \"cuda out of memory\" in msg:\n",
        "            torch.cuda.empty_cache()\n",
        "            print(f\" ‚ö†Ô∏è OOM on full-res for {image_path}. Resizing to 448x448 and retrying‚Ä¶\")\n",
        "            try:\n",
        "                img = Image.open(image_path).convert(\"RGB\")\n",
        "                img = img.resize((448, 448))\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".jpg\", delete=False) as tmp:\n",
        "                    tmp_path = tmp.name\n",
        "                    img.save(tmp_path, format=\"JPEG\")\n",
        "                raw_output = infer_img(tmp_path, prompt)\n",
        "                print(\" ‚Üí infer_img() succeeded (resized).\")\n",
        "            except Exception as e2:\n",
        "                print(f\" ‚ùå Failed even after resize: {e2}\")\n",
        "                raw_output = None\n",
        "        else:\n",
        "            print(f\" ‚ùå RuntimeError on {image_path}: {e}\")\n",
        "            raw_output = None\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå Error processing {image_path}: {e}\")\n",
        "        raw_output = None\n",
        "\n",
        "    # Produce a single canonical 'output' value:\n",
        "    # - If model returned a dict/list already -> normalize and use that\n",
        "    # - If model returned a string -> try parse JSON; if success use parsed normalized,\n",
        "    #   else keep original string\n",
        "    output_value = None\n",
        "    if raw_output is None:\n",
        "        output_value = None\n",
        "        print(\" ‚Üí No output from model.\")\n",
        "    else:\n",
        "        if isinstance(raw_output, (dict, list)):\n",
        "            output_value = normalize(raw_output)\n",
        "            print(f\" ‚Üí Model returned {type(raw_output).__name__}; stored structured output.\")\n",
        "        elif isinstance(raw_output, str):\n",
        "            parsed, perr = try_parse_json_from_string(raw_output)\n",
        "            if parsed is not None:\n",
        "                output_value = normalize(parsed)\n",
        "                print(\" ‚Üí Parsed JSON from model string; stored structured output.\")\n",
        "            else:\n",
        "                # keep the original string (no duplication)\n",
        "                output_value = raw_output\n",
        "                print(f\" ‚Üí Could not parse JSON from model string: {perr!s}. Keeping raw string as output.\")\n",
        "        else:\n",
        "            # for bytes, numbers, etc., keep as-is\n",
        "            output_value = raw_output\n",
        "            print(f\" ‚Üí Model returned type {type(raw_output).__name__}; keeping as output.\")\n",
        "\n",
        "\n",
        "    result = {\n",
        "        \"image_path\":   image_path,\n",
        "        \"model\":        MODEL_NAME,\n",
        "        \"variant\":      VARIANT,\n",
        "        \"task\":         TASK,\n",
        "        \"task_level\":   TASK_LEVEL,\n",
        "        \"prompt_level\": PROMPT_LEVEL,\n",
        "        \"run_count\":    RUN_COUNT,\n",
        "        \"prompt\":       prompt,\n",
        "        \"output\":       output_value\n",
        "    }\n",
        "    results.append(result)\n",
        "    print(f\"\\nOutput:\\n{output_value}\\n\")\n",
        "\n",
        "    # Save progress\n",
        "    try:\n",
        "        save_results(results, MODEL_NAME, VARIANT, TASK, TASK_LEVEL, PROMPT_LEVEL, RUN_COUNT)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" ‚ùå Failed to save results: {e}\")\n",
        "\n",
        "    # always clear GPU cache\n",
        "    torch.cuda.empty_cache()\n",
        "    print(f\"Total files done: {i+1}\")\n",
        "    print(\"\\n######################################################\\n\")\n"
      ],
      "metadata": {
        "id": "_1d3F2vJycoR",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:58:35.371886Z",
          "iopub.execute_input": "2025-10-06T09:58:35.372622Z",
          "iopub.status.idle": "2025-10-06T09:59:52.988064Z",
          "shell.execute_reply.started": "2025-10-06T09:58:35.372598Z",
          "shell.execute_reply": "2025-10-06T09:59:52.986797Z"
        },
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-10-06T09:55:20.585348Z",
          "iopub.status.idle": "2025-10-06T09:55:20.585675Z",
          "shell.execute_reply.started": "2025-10-06T09:55:20.585510Z",
          "shell.execute_reply": "2025-10-06T09:55:20.585524Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "VnauO_VCbC3N"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}
